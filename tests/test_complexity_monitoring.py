#!/usr/bin/env python3
"""
CSV Complexity Testing Framework
Tests system monitoring authenticity by processing graduated complexity datasets
"""

import requests
import time
import json
import asyncio
import websockets
import psutil
from datetime import datetime
import sys

BASE_URL = "http://localhost:8000"
WS_URL = "ws://localhost:8000/ws"

class ComplexityMonitor:
    def __init__(self):
        self.baseline_metrics = None
        self.test_results = {}
        
    def capture_system_metrics(self):
        """Capture current system metrics using psutil"""
        return {
            'timestamp': datetime.now().isoformat(),
            'cpu_percent': psutil.cpu_percent(interval=1),
            'memory_percent': psutil.virtual_memory().percent,
            'memory_used_mb': psutil.virtual_memory().used // 1024 // 1024,
            'disk_percent': psutil.disk_usage('/').percent,
            'process_count': len(psutil.pids())
        }
    
    def capture_baseline(self):
        """Capture system baseline metrics"""
        print("\nüìä Capturing baseline system metrics...")
        self.baseline_metrics = self.capture_system_metrics()
        print(f"  CPU: {self.baseline_metrics['cpu_percent']:.1f}%")
        print(f"  Memory: {self.baseline_metrics['memory_percent']:.1f}% ({self.baseline_metrics['memory_used_mb']}MB)")
        print(f"  Processes: {self.baseline_metrics['process_count']}")
        return self.baseline_metrics
    
    async def monitor_websocket_metrics(self, job_id):
        """Monitor WebSocket metrics during training"""
        metrics_captured = []
        
        try:
            async with websockets.connect(WS_URL) as websocket:
                start_time = time.time()
                
                while True:
                    try:
                        message = await asyncio.wait_for(websocket.recv(), timeout=10)
                        data = json.loads(message)
                        
                        # Capture system metrics
                        if data.get('type') == 'system_metrics':
                            metrics_captured.append({
                                'timestamp': data.get('timestamp'),
                                'cpu_percent': data.get('cpu_percent'),
                                'memory_percent': data.get('memory_percent'),
                                'active_connections': data.get('active_connections'),
                                'ws_response_time_ms': data.get('ws_response_time_ms')
                            })
                        
                        # Check for training completion
                        if data.get('type') == 'training_completed' and data.get('job_id') == job_id:
                            print(f"    ‚úÖ Training completed: {data.get('final_accuracy', 0):.1%} accuracy")
                            break
                            
                        # Check for training failure
                        if data.get('type') == 'training_failed' and data.get('job_id') == job_id:
                            print(f"    ‚ùå Training failed: {data.get('error', 'Unknown error')}")
                            break
                            
                        # Timeout after 5 minutes
                        if time.time() - start_time > 300:
                            print("    ‚ö†Ô∏è  Training timeout - stopping monitoring")
                            break
                            
                    except asyncio.TimeoutError:
                        continue
                        
        except Exception as e:
            print(f"    ‚ùå WebSocket monitoring error: {e}")
            
        return metrics_captured
    
    def upload_dataset(self, dataset_name, filepath):
        """Upload a CSV dataset"""
        print(f"\nüì§ Uploading {dataset_name} dataset...")
        
        try:
            with open(filepath, 'rb') as f:
                files = {'file': (filepath.split('/')[-1], f, 'text/csv')}
                response = requests.post(f"{BASE_URL}/api/upload", files=files, timeout=30)
            
            if response.status_code == 200:
                result = response.json()
                print(f"  ‚úÖ Uploaded: {result['filename']} ({result['rows']} rows, {result['columns']} columns)")
                return result['file_path']
            else:
                print(f"  ‚ùå Upload failed: Status {response.status_code}")
                return None
                
        except Exception as e:
            print(f"  ‚ùå Upload error: {e}")
            return None
    
    def start_training(self, file_path):
        """Start model training"""
        print("  ü§ñ Starting model training...")
        
        try:
            training_request = {
                'model_type': 'automatic',
                'file_path': file_path
            }
            response = requests.post(f"{BASE_URL}/api/train", json=training_request, timeout=10)
            
            if response.status_code == 200:
                result = response.json()
                print(f"  ‚úÖ Training started: Job ID {result['job_id']}")
                return result['job_id']
            else:
                print(f"  ‚ùå Training failed to start: Status {response.status_code}")
                return None
                
        except Exception as e:
            print(f"  ‚ùå Training error: {e}")
            return None
    
    async def test_single_complexity(self, name, dataset_filename):
        """Test a single complexity level"""
        print(f"\n{'='*60}")
        print(f"üß™ Testing {name} Complexity Dataset")
        print(f"{'='*60}")
        
        # Capture pre-training metrics
        pre_metrics = self.capture_system_metrics()
        
        # Upload dataset
        upload_start = time.time()
        file_path = self.upload_dataset(name, dataset_filename)
        upload_duration = time.time() - upload_start
        
        if not file_path:
            print("  ‚ö†Ô∏è  Skipping training due to upload failure")
            return None
        
        # Start training
        training_start = time.time()
        job_id = self.start_training(file_path)
        
        if not job_id:
            print("  ‚ö†Ô∏è  Skipping monitoring due to training start failure")
            return None
        
        # Monitor WebSocket metrics during training
        print("  üìä Monitoring system metrics during training...")
        websocket_metrics = await self.monitor_websocket_metrics(job_id)
        training_duration = time.time() - training_start
        
        # Capture post-training metrics
        post_metrics = self.capture_system_metrics()
        
        # Calculate differences
        cpu_increase = post_metrics['cpu_percent'] - pre_metrics['cpu_percent']
        memory_increase = post_metrics['memory_used_mb'] - pre_metrics['memory_used_mb']
        
        # Find peak metrics from WebSocket data
        peak_cpu = max([m['cpu_percent'] for m in websocket_metrics], default=0)
        peak_memory = max([m['memory_percent'] for m in websocket_metrics], default=0)
        
        print(f"\n  üìà Results:")
        print(f"    Upload time: {upload_duration:.1f}s")
        print(f"    Training time: {training_duration:.1f}s")
        print(f"    CPU increase: +{cpu_increase:.1f}%")
        print(f"    Memory increase: +{memory_increase}MB")
        print(f"    Peak CPU (WebSocket): {peak_cpu:.1f}%")
        print(f"    Peak Memory (WebSocket): {peak_memory:.1f}%")
        print(f"    WebSocket samples: {len(websocket_metrics)}")
        
        return {
            'dataset': name,
            'filename': dataset_filename,
            'pre_metrics': pre_metrics,
            'post_metrics': post_metrics,
            'websocket_metrics': websocket_metrics,
            'upload_duration': upload_duration,
            'training_duration': training_duration,
            'cpu_increase': cpu_increase,
            'memory_increase': memory_increase,
            'peak_cpu': peak_cpu,
            'peak_memory': peak_memory
        }
    
    def wait_for_cooldown(self):
        """Wait for system to return to baseline"""
        print("\n‚è≥ Waiting for system cooldown...")
        
        baseline_cpu = self.baseline_metrics['cpu_percent']
        cooldown_start = time.time()
        
        while True:
            current_cpu = psutil.cpu_percent(interval=1)
            if current_cpu <= baseline_cpu + 5:  # Within 5% of baseline
                break
            if time.time() - cooldown_start > 30:  # Max 30 seconds cooldown
                print("  ‚ö†Ô∏è  Cooldown timeout - continuing anyway")
                break
            print(f"  Cooling down... CPU: {current_cpu:.1f}%")
            time.sleep(2)
        
        print("  ‚úÖ System cooled down")
    
    async def run_complexity_tests(self):
        """Run all complexity tests"""
        print("\nüöÄ CSV Complexity Testing Framework")
        print("Testing system monitoring authenticity with graduated datasets")
        
        # Capture baseline
        self.capture_baseline()
        
        # Test datasets
        datasets = [
            ('Simple', 'uploads/test_simple.csv'),
            ('Medium', 'uploads/test_medium.csv'),
            ('Complex', 'uploads/test_complex.csv')
        ]
        
        # Run tests
        for name, filepath in datasets:
            result = await self.test_single_complexity(name, filepath)
            if result:
                self.test_results[name] = result
            
            # Cooldown between tests
            if name != 'Complex':  # No cooldown after last test
                self.wait_for_cooldown()
        
        # Generate report
        self.generate_report()
    
    def generate_report(self):
        """Generate comprehensive comparison report"""
        print("\n" + "="*60)
        print("üìä COMPLEXITY TESTING RESULTS")
        print("="*60)
        
        if not self.test_results:
            print("‚ùå No test results available")
            return
        
        print(f"\nBaseline System State:")
        print(f"  CPU: {self.baseline_metrics['cpu_percent']:.1f}%")
        print(f"  Memory: {self.baseline_metrics['memory_percent']:.1f}% ({self.baseline_metrics['memory_used_mb']}MB)")
        
        # Compare results
        for name in ['Simple', 'Medium', 'Complex']:
            if name not in self.test_results:
                continue
                
            result = self.test_results[name]
            print(f"\n{name} Dataset Results:")
            print(f"  Training Time: {result['training_duration']:.1f}s")
            print(f"  Peak CPU: {result['peak_cpu']:.1f}% (+{result['peak_cpu'] - self.baseline_metrics['cpu_percent']:.1f}%)")
            print(f"  Peak Memory: {result['peak_memory']:.1f}%")
            print(f"  CPU Increase: +{result['cpu_increase']:.1f}%")
            print(f"  Memory Increase: +{result['memory_increase']}MB")
        
        # Verify progression
        if len(self.test_results) >= 3:
            simple_cpu = self.test_results.get('Simple', {}).get('peak_cpu', 0)
            medium_cpu = self.test_results.get('Medium', {}).get('peak_cpu', 0)
            complex_cpu = self.test_results.get('Complex', {}).get('peak_cpu', 0)
            
            simple_time = self.test_results.get('Simple', {}).get('training_duration', 0)
            medium_time = self.test_results.get('Medium', {}).get('training_duration', 0)
            complex_time = self.test_results.get('Complex', {}).get('training_duration', 0)
            
            print("\n‚úÖ VALIDATION RESULTS:")
            print(f"  CPU Progression: {simple_cpu:.1f}% ‚Üí {medium_cpu:.1f}% ‚Üí {complex_cpu:.1f}%")
            print(f"  Time Progression: {simple_time:.1f}s ‚Üí {medium_time:.1f}s ‚Üí {complex_time:.1f}s")
            
            # Verify authenticity
            if medium_cpu > simple_cpu and complex_cpu > medium_cpu:
                print("\nüéØ PROOF: System monitoring reflects REAL workload variations!")
                print("  ‚úì CPU usage increases with dataset complexity")
                print("  ‚úì Training time scales with data size")
                print("  ‚úì WebSocket metrics match system state")
                print("  ‚úì Monitoring is AUTHENTIC, not simulated!")
            else:
                print("\n‚ö†Ô∏è  WARNING: Expected progression not observed")

def main():
    """Main entry point"""
    if len(sys.argv) > 1:
        if sys.argv[1] == '--baseline-only':
            monitor = ComplexityMonitor()
            monitor.capture_baseline()
            return
    
    # Run full test suite
    monitor = ComplexityMonitor()
    asyncio.run(monitor.run_complexity_tests())

if __name__ == "__main__":
    main()